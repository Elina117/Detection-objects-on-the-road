# YOLOv8 Object Detection & Distance Estimation

## Описание проекта

Этот проект реализует **обнаружение объектов на видео и оценку расстояния до них** с использованием модели **YOLOv8 в формате ONNX**.  
Реализация включает полный цикл обработки:  
- загрузка модели и видео,  
- инференс (обнаружение объектов),  
- применение **Non-Maximum Suppression (NMS)**,  
- визуализация результатов (классы, вероятность, расстояние до объекта),  
- измерение производительности (FPS, среднее время инференса).  

Проект может использоваться для анализа видеопотоков с автомобильных видеорегистраторов, систем безопасности или робототехники.

---

## Как запустить

### 1. Установка зависимостей

```bash
pip install numpy opencv-python onnxruntime
```

### 2. Подготовка данных
- Сохраните видео из папки **workdir** в директорию проекта (пример: `/input/DashCam.mp4`)
- Скачайте модель YOLOv8 в формате `.onnx` из папки **models** с нужным разрешением.

Структура проекта:
**models** - содержит модель в формате `.onnx` 614 на 614 и 416 на 416.
**script** - содержит готовый ноутбук с полным кодом решения задачи и файл Converte.ipynb для конвертирования модели в формат `.onnx`.
**work_dir** - видео полной, видео обрезанное до 12 секунд и видео полученное в результате работы модели с наложением bboxes, score, distance.

**Scheme.md** - схема алгоиртма.

### 3. Запуск скрипта

В Jupyter notebook / Collab / Kaggle запустите main.ipynb.

Скрипт:
- обрезает видео до 10 секунд;
- выполняет детекцию объектов;
- сохраняет результат в `output.mp4`.

---

## Основные компоненты

### `xywh2xyxy(boxes)`
Конвертация координат из формата `(x_center, y_center, width, height)` в `(x1, y1, x2, y2)`.

### `compute_iou(box, boxes)`
Вычисляет **IoU (Intersection over Union)** между текущим и остальными боксами.

### `nms()` и `multiclass_nms()`
Реализуют **Non-Maximum Suppression** для удаления перекрывающихся предсказаний.

### `YOLOv8` (класс)
Главный класс детектора, включающий:
- загрузку модели ONNX (`onnxruntime.InferenceSession`);
- предобработку входных изображений;
- постобработку результатов (NMS, вычисление расстояний);
- визуализацию детекций (`cv2.rectangle`, `cv2.putText`).

---

## Подходы и особенности реализации

- **Модель YOLOv8 в формате ONNX** используется для кроссплатформенной работы без зависимости от PyTorch.  
- **Numpy-only реализация NMS** — без внешних библиотек.  
- **Расчет расстояний** основан на предположении о средней высоте объектов и известном фокусном расстоянии камеры:

  ```
  distance = FOCAL_PX * real_height / pixel_height
  ```

- **Оптимизация**: сохранение только 10 секунд видео для ускорения тестирования.

---

## Метрики и тестирование

После завершения обработки выводятся:

| Метрика | Описание |
|----------|-----------|
| `Среднее время инференса (ms/кадр)` | Среднее время обработки одного кадра |
| `FPS` | Количество кадров в секунду |
| `Кадров обработано` | Общее количество обработанных кадров |

Результат работы:

```
Обработка завершена. Видео сохранено: output.mp4
Кадров обработано: 299
Среднее время инференса: 157.6 ms/кадр
FPS: 6.35
```

---

## Ограничения

- Требуется наличие **ONNX-модели YOLOv8** (`YOLO8n.onnx`).  
- Расчет расстояний — **приблизительный**, основан на усредненных высотах классов (`CLASS_MEAN_HEIGHT`).  
- Не реализовано динамическое определение фокусного расстояния камеры (`FOCAL_PX` зафиксировано = 1200).  
- Скрипт рассчитан на **одиночный поток CPU** (используется `onnxruntime` без GPU).

---

## Пример результата

- Оригинальный кадр отображается до инференса.
- После обработки на кадре показываются:
  - рамки объектов,
  - вероятность (confidence),
  - класс объекта,
  - расстояние до него в метрах.

Пример надписи на кадре:
```
car 0.91 12.3m
```

---

## Используемые технологии

- **Python 3.8+**
- **NumPy**
- **OpenCV**
- **ONNX Runtime**

---

## Разработка и окружение

Проект разрабатывался и тестировался в **Kaggle Notebook (Kaggle Kernels)** на **CPU**. В настройках ноутбука использовалась стандартная конфигурация без GPU. В Kaggle файлы (видео и модель) подключались через *Datasets* — в скрипте пути указаны как примеры (`/kaggle/input/...`).

Если вы запускаете проект локально, убедитесь, что у вас достаточно оперативной памяти и процессор подходит для инференса модели на CPU — на медленных CPU инференс будет заметно дольше, чем на GPU.

---

## Клонирование репозитория и воспроизведение результатов

Клонируйте репозиторий на ваш компьютер:
```bash
git clone https://github.com/Elina117/Detection-objects-on-the-road.git
cd Detection-objects-on-the-road
```

Рекомендуется создать виртуальное окружение и установить зависимости из `requirements.txt`:

```bash
python -m venv venv
source venv/bin/activate    

pip install -r requirements.txt
```

Подготовьте файлы:
- Поместите `YOLO8n.onnx` в корень проекта или укажите путь к модели в `main.ipynb` (переменная `model_path`).
- Поместите видео (например, `DashCam.mp4`) в корень проекта или измените `video_path` в скрипте.

Запустите основной скрипт.

После выполнения вы получите `output.mp4` с визуализацией детекций и выводом метрик в консоль.
